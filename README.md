# Intern-with-atomic
This is a over view of what was done during my week long intership with Atomic. During the one week time period we learned how to use node, and puppeteer to go through and scrap information off of a webiste. The website they provided was https://www.imdb.com/title/tt1396484/. With this website they had us go through and find the xpaths of the title, rating, summary, length. With this information when we would use our local host it would populate that information. After we we're able to scrap that information then we went back through and simified the xpaths by usign chromes inspect tool to get the orginal xpath and go thorugh and find a class name, id , href and etc. Then use the simpified path to better point to our title, rating , etc. It allowed the code we created to be more readible. Then we went back through and scraped all the actors for that film along with there id's. We as well used the scrapping to get just a single actor name as well through a seperate local host. We as well used debugging to walk through code to make sure it was working. We used testing envirments nad took snapshots to make sure we had no error codes returned and that everything passed and was working well before being commited into the master. To add to this the way things we're set up was meant for a mac os system. There was a few of us using windows and had to set up a vitual machine with lenox and wsl with our vs code to get all of this to work.  Then towards the end of the week the last few days we focused on reverse engineering Domino's website to be able to order pizza through our code. We used postman, mitmproxy and Domino's webiste. We used mitmproxy to track / read the http get and post responses. We then pin pointed to the most inportant get and post responses and used those in postman to set up our code so then at the last day of the Internship we would be given a card information and order pizza.  
